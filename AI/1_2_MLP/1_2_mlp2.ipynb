{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "ZyH7ohm-FMCT",
        "outputId": "c66155af-e4df-4fd0-92e2-41321da42d50"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1300x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n",
        "X = digits.data.astype(np.float32)\n",
        "y = digits.target.astype(np.int64)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(13, 5), nrows=2, ncols=5)\n",
        "for i in range(10):\n",
        "    ax[i // 5, i % 5].imshow(X[i].reshape(8, 8), cmap=\"gray\")\n",
        "    ax[i // 5, i % 5].set_title(f\"Label: {y[i]}\")\n",
        "    ax[i // 5, i % 5].axis(\"off\")\n",
        "fig.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 우선 8:2 로 나누기\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)\n",
        "\n",
        "# 2를 다시 1:1로 나누기\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify = y_temp)\n",
        "\n",
        "# 표준화\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "7dCkphTGFiLz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 데이터를 텐서로 변환\n",
        "X_train_t = torch.from_numpy(X_train)\n",
        "y_train_t = torch.from_numpy(y_train)\n",
        "X_valid_t = torch.from_numpy(X_valid)\n",
        "y_valid_t = torch.from_numpy(y_valid)\n",
        "X_test_t = torch.from_numpy(X_test)\n",
        "y_test_t = torch.from_numpy(y_test)\n",
        "\n",
        "# Pytorch TensorDataset에 넣어주기\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_ds = TensorDataset(X_train_t, y_train_t)\n",
        "valid_ds = TensorDataset(X_valid_t, y_valid_t)\n",
        "test_ds = TensorDataset(X_test_t, y_test_t)\n",
        "\n",
        "# TensorDataset을 DataLoader로 변환\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_ds, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "8dYV2J-dGZfA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, batch in enumerate(train_loader):\n",
        "    print(idx, batch)\n",
        "    print(len(batch[1]))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiSbr2LaH2t8",
        "outputId": "793c337c-e587-43fe-ec7b-c2708a2adb51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [tensor([[ 0.0000, -0.3305, -1.0952,  ..., -0.8197, -0.5045, -0.1936],\n",
            "        [ 0.0000, -0.3305, -1.0952,  ..., -1.1588, -0.5045, -0.1936],\n",
            "        [ 0.0000, -0.3305, -1.0952,  ..., -1.1588, -0.5045, -0.1936],\n",
            "        ...,\n",
            "        [ 0.0000, -0.3305, -0.0347,  ..., -0.4807, -0.5045, -0.1936],\n",
            "        [ 0.0000, -0.3305,  0.6016,  ...,  1.3843,  0.7189, -0.1936],\n",
            "        [ 0.0000, -0.3305,  0.8137,  ...,  1.5538,  3.4106,  2.7044]]), tensor([4, 4, 8, 5, 4, 0, 9, 0, 5, 8, 9, 2, 6, 0, 8, 4, 5, 5, 0, 1, 6, 3, 0, 9,\n",
            "        2, 0, 2, 3, 9, 1, 3, 2])]\n",
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# 3. Multi-Layer Perceptron 구현하기\n",
        "# 가장 기본적인 MultiLayer Perceptron을 구현해주세요.\n",
        "# 계층은 총 3개입니다.\n",
        "# 입력표현 -> 은닉표현1 -> 은닉표현2 -> 출력표현\n",
        "# 입력값들은 `nn.Linear`를 통과한 뒤 ReLU를 거치고 Dropout을 거치도록 설계해주세요.\n",
        "# 제가 정의해준 `__init__` 안의 인자에 맞춰서 작업해주세요 :)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 num_classes: int,\n",
        "                 hidden_dims=(128, 64),\n",
        "                 dropout=0.2):\n",
        "        super().__init__()\n",
        "        h1, h2 = hidden_dims\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            # 은닉1\n",
        "            nn.Linear(input_dim, h1),\n",
        "            # 활성화 + Dropout\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            # 은닉2 (입력 차원은 은닉1의 출력차원)\n",
        "            nn.Linear(h1, h2),\n",
        "            # 활성화 + Dropout\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            # 출력\n",
        "            nn.Linear(h2, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "8mM2czLkIERl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정답코드\n",
        "# 4. DataLoader, Model, Optimizer가 주어졌을 때\n",
        "# 학습데이터에 대해 model을 업데이트하는 코드를 작성해주세요.\n",
        "def train_one_epoch(model, loader, optimizer, device):\n",
        "    # 모델이 학습모드로 들어가게 설정해야합니다.\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for xb, yb in loader:\n",
        "        # 데이터를 가속화기기로 보내주세요.\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        # 위에서 배운 파라미터 업데이트 방식을 구현해주세요.\n",
        "        # 1. 모델의 출력 만들어주기\n",
        "        # 2. 미분값 지워주기 (zero_grad)\n",
        "        # 3. Loss 계산해주기: loss는 cross_entropy를 사용해주세요\n",
        "        #   - https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html\n",
        "        # 4. 3에서 계산한 Loss를 기준으로 역전파를 수행합니다.\n",
        "        # 5. 파라미터 업데이트를 진행해주세요\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = torch.nn.functional.cross_entropy(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 파라미터 업데이트가 끝났으면 몇 가지를 기록해줍니다.\n",
        "        # 1. batch당 로스 계산 (running_loss에 업데이트)\n",
        "        # 2. 예측된 클래스 계산 (`preds`)\n",
        "        # 3. batch 내 정확도 계산 (batch 내에서 정답개수를 correct에 추가)\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "\n",
        "    # 위에서 잘 계산된 값들을 정리해서 반환합니다.\n",
        "    avg_loss = running_loss / total\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc\n",
        "\n",
        "# 정답코드\n",
        "# 5. 이번에는 모델과 검증/테스트데이터가 입력으로 들어왔을 때 정확도를 계산해주는 코드를 작성해주세요.\n",
        "def evaluate(model, loader, device):\n",
        "    # 모델이 추론할 때는 추론모드로 설정해주어야합니다.\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    # 미분그래프를 생성하지 않도록 컨텍스트를 생성해주셔야합니다.\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            # 데이터로더에서 나온 배치를 `device`로 보내주세요.\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            # 위에서 한 것과 비슷하게\n",
        "            # 모델의 출력값을 만들어 `logits`에 담고\n",
        "            # 현재 출력값 `logits`와 `yb` 사이의 Cross Entropy를 계산해주세요.\n",
        "            logits = model(xb)\n",
        "            loss = torch.nn.functional.cross_entropy(logits, yb)\n",
        "\n",
        "            # 이번에도 다음을 기록해줍니다.\n",
        "            # 1. batch당 로스 계산 (running_loss에 update)\n",
        "            # 2. 예측된 클래스 계산 (`preds`)\n",
        "            # 3. batch 내 정확도 계산 (batch 내에서 정답개수를 correct에 추가)\n",
        "            # 4. 후에 정확한 분류성능을 보기 위해 prediction 값들도 전부 기록해줍니다.\n",
        "            #  - all_preds, all_targets에 append해줍니다.\n",
        "            running_loss += loss.item() * xb.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_targets.append(yb.cpu())\n",
        "\n",
        "    # 위에서 잘 계산된 값들을 정리해서 반환합니다.\n",
        "    avg_loss = running_loss / total\n",
        "    acc = correct / total\n",
        "    preds_cat = torch.cat(all_preds).numpy()\n",
        "    targets_cat = torch.cat(all_targets).numpy()\n",
        "    return avg_loss, acc, preds_cat, targets_cat"
      ],
      "metadata": {
        "id": "28gnNDRFKtt5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 것을 하나로!\n",
        "# 여러분이 코드를 잘 짰다면 아래 코드가 잘 작동할겁니다!\n",
        "# 에러가 뜬다면 에러메시지를 확인해서 잘 구현되도록 맞춰주세요.\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# device = torch.device(\"cuda\")\n",
        "model = MLP(\n",
        "    input_dim=64,\n",
        "    num_classes=10,\n",
        "    hidden_dims=(128, 64),\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "# 이번에는 지난 과제2에서 배웠던 Adam을 사용해봅시다.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "best_val_loss = math.inf\n",
        "best_val_acc = -1.0\n",
        "epochs_no_improve = 0\n",
        "\n",
        "checkpoint_path = \"model.ckpt\"\n",
        "earlystop_patience = 5\n",
        "\n",
        "train_losses, train_accs = [], []\n",
        "valid_losses, valid_accs = [], []\n",
        "for epoch in range(1, 201):\n",
        "    t0 = time.time()\n",
        "    # 여러분이 정의한 `train_one_epoch`와 `evaluate`입니다.\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "    val_loss, val_acc, _, _ = evaluate(model, valid_loader, device)\n",
        "    valid_losses.append(val_loss)\n",
        "    valid_accs.append(val_acc)\n",
        "\n",
        "    dt = time.time() - t0\n",
        "    print(\n",
        "        f\"Epoch {epoch:03d} | \"\n",
        "        f\"train loss {train_loss:.4f} acc {train_acc*100:5.2f}% | \"\n",
        "        f\"val loss {val_loss:.4f} acc {val_acc*100:5.2f}% | \"\n",
        "        f\"{dt:.1f}s\"\n",
        "    )\n",
        "\n",
        "    # 🌟 개선 시 체크포인트 저장\n",
        "    improved = (val_loss < best_val_loss) or (val_acc > best_val_acc)\n",
        "    if improved:\n",
        "        best_val_loss = min(best_val_loss, val_loss)\n",
        "        best_val_acc = max(best_val_acc, val_acc)\n",
        "        torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'input_dim': 64,\n",
        "            'num_classes': 10,\n",
        "        }, checkpoint_path)\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "\n",
        "    # 조기 종료\n",
        "    if epochs_no_improve >= earlystop_patience:\n",
        "        print(f\"Early stopping at epoch {epoch} (no improve {earlystop_patience})\")\n",
        "        break\n",
        "\n",
        "# 베스트 모델 로드 후 테스트 평가\n",
        "if os.path.exists(checkpoint_path):\n",
        "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(ckpt['model_state_dict'])\n",
        "    print(f\"Loaded best checkpoint: val_best_acc={best_val_acc*100:.2f}% val_best_loss={best_val_loss:.4f}\")\n",
        "\n",
        "test_loss, test_acc, y_pred, y_true = evaluate(model, test_loader, device)\n",
        "print(\"\\n==== Test Result ====\")\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test acc : {test_acc*100:.2f}%\")\n",
        "\n",
        "# 분류 리포트 / 혼동행렬\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "aZx_BIivK8oG",
        "outputId": "65e01ec5-1e8d-4685-c266-5cca2fb89278"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "train_one_epoch() missing 1 required positional argument: 'device'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-353921631.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# 여러분이 정의한 `train_one_epoch`와 `evaluate`입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtrain_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: train_one_epoch() missing 1 required positional argument: 'device'"
          ]
        }
      ]
    }
  ]
}